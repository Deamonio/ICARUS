import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from ultralytics import YOLO
from PIL import Image
import matplotlib.pyplot as plt
import csv
import numpy as np
from datetime import datetime
import glob
import random
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2

# ==========================================
# 1. ë°ì´í„°ì…‹ ì •ì˜ (ì¢Œí‘œ ë³€í™˜ ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ)
# ==========================================
class CupDataset(Dataset):
    def __init__(self, img_dir, label_dir, img_size=800, augment=False):
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.img_size = img_size
        self.augment = augment
        
        # Stage 3: ì¦ê°• ì™„ì „ ì œê±° (ì›ë³¸ ë°ì´í„°ì—ë§Œ ì§‘ì¤‘)
        # augment íŒŒë¼ë¯¸í„°ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ë‚¨ê²¨ë‘ì§€ë§Œ, Stage 3ì—ì„œëŠ” í•­ìƒ False
        self.transform = A.Compose([
            A.LongestMaxSize(max_size=img_size),
            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=(114, 114, 114)),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2()
        ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False),
           bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))

        # ìœ íš¨í•œ ìƒ˜í”Œë§Œ í•„í„°ë§ (ì´ë¯¸ì§€ ì¡´ì¬ + ë¼ë²¨ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ í˜•ì‹)
        all_images = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]
        self.valid_samples = []
        invalid_count = 0
        
        for img_name in all_images:
            label_path = os.path.join(label_dir, img_name.rsplit('.', 1)[0] + '.txt')
            if not os.path.exists(label_path):
                invalid_count += 1
                continue
            
            # ë¼ë²¨ íŒŒì¼ ê²€ì¦
            try:
                with open(label_path, 'r') as f:
                    line = f.readline().split()
                    if len(line) >= 7:  # class + 4 bbox + 2 keypoints
                        self.valid_samples.append(img_name)
                    else:
                        invalid_count += 1
            except:
                invalid_count += 1
        
        if invalid_count > 0:
            print(f"Filtered out {invalid_count} invalid samples. Valid samples: {len(self.valid_samples)}")

    def __len__(self):
        return len(self.valid_samples)

    def __getitem__(self, idx):
        img_name = self.valid_samples[idx]
        img_path = os.path.join(self.img_dir, img_name)
        label_path = os.path.join(self.label_dir, img_name.rsplit('.', 1)[0] + '.txt')
        
        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        h_orig, w_orig = image.shape[:2]

        with open(label_path, 'r') as f:
            line = f.readline().split()
            
            # ë¼ë²¨ íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš° ì²´í¬
            if len(line) < 7:
                raise ValueError(f"Label file {label_path} has insufficient data. Expected at least 7 values, got {len(line)}")
            
            # YOLO í˜•ì‹: [cx, cy, w, h]
            cx, cy, w, h = [float(x) for x in line[1:5]]
            
            # YOLO -> xyxy ë³€í™˜í•˜ì—¬ ë°•ìŠ¤ê°€ ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šë„ë¡ í´ë¨í”„
            x_min = np.clip(cx - w/2, 0.0, 1.0)
            y_min = np.clip(cy - h/2, 0.0, 1.0)
            x_max = np.clip(cx + w/2, 0.0, 1.0)
            y_max = np.clip(cy + h/2, 0.0, 1.0)
            
            # ë‹¤ì‹œ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ì™„ì „ ì œê±°ë¥¼ ìœ„í•´ í•œë²ˆ ë” í´ë¨í”„)
            cx_clipped = np.clip((x_min + x_max) / 2, 0.0, 1.0)
            cy_clipped = np.clip((y_min + y_max) / 2, 0.0, 1.0)
            w_clipped = np.clip(x_max - x_min, 0.0, 1.0)
            h_clipped = np.clip(y_max - y_min, 0.0, 1.0)
            bbox = [cx_clipped, cy_clipped, w_clipped, h_clipped]
            
            # Point í˜•ì‹: [px, py] -> í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜í•˜ì—¬ ì¦ê°•ê¸°ì— ì „ë‹¬
            keypoint = [[np.clip(float(line[5]), 0.0, 1.0) * w_orig, 
                        np.clip(float(line[6]), 0.0, 1.0) * h_orig]]

        # Stage 3: ì¦ê°• ì—†ì´ ë³€í™˜ë§Œ ì ìš©
        transformed = self.transform(image=image, bboxes=[bbox], class_labels=[0], keypoints=keypoint)
        
        image = transformed['image']
        # ë³€í˜• í›„ ë‹¤ì‹œ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”ëœ ì¢Œí‘œ ì¶”ì¶œ
        box_target = torch.tensor(transformed['bboxes'][0], dtype=torch.float32)
        point_target = torch.tensor([transformed['keypoints'][0][0] / self.img_size, 
                                    transformed['keypoints'][0][1] / self.img_size], dtype=torch.float32)

        return image, box_target, point_target

# ==========================================
# 2. ëª¨ë¸ ì •ì˜ (Full Training ëª¨ë“œ)
# ==========================================
class ExpandedHead(nn.Module):
    """í™•ì¥ëœ í—¤ë“œ: ë” ê¹Šê³  ë„“ì€ êµ¬ì¡°ë¡œ í‘œí˜„ë ¥ í–¥ìƒ"""
    def __init__(self, input_dim, hidden_dim=1024, output_dim=4):
        super().__init__()
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.flatten = nn.Flatten()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),  # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë“œë¡­ì•„ì›ƒ ì¶”ê°€
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, output_dim),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        x = self.pool(x)
        x = self.flatten(x)
        return self.fc(x)

class YOLOFullTaskModel(nn.Module):
    def __init__(self):
        super(YOLOFullTaskModel, self).__init__()
        base_model = YOLO('yolov8m-pose.pt').model
        self.feature_extractor = base_model.model[:10] # Backbone
        
        feature_dim = 576  # YOLOv8m-pose backbone[:10] output dimension
        
        # í™•ì¥ëœ í—¤ë“œ ì‚¬ìš© (ë” ê¹Šê³  ë„“ì€ êµ¬ì¡°)
        self.box_head = ExpandedHead(input_dim=feature_dim, hidden_dim=1024, output_dim=4)
        self.point_head = ExpandedHead(input_dim=feature_dim, hidden_dim=1024, output_dim=2)

    def forward(self, x):
        features = self.feature_extractor(x)
        return self.box_head(features), self.point_head(features)

# ==========================================
# 3. TTA ë° í‰ê°€ í•¨ìˆ˜
# ==========================================
def calculate_iou(box1, box2):
    """IoU ê³„ì‚°"""
    box1_x1 = box1[:, 0] - box1[:, 2] / 2
    box1_y1 = box1[:, 1] - box1[:, 3] / 2
    box1_x2 = box1[:, 0] + box1[:, 2] / 2
    box1_y2 = box1[:, 1] + box1[:, 3] / 2
    
    box2_x1 = box2[:, 0] - box2[:, 2] / 2
    box2_y1 = box2[:, 1] - box2[:, 3] / 2
    box2_x2 = box2[:, 0] + box2[:, 2] / 2
    box2_y2 = box2[:, 1] + box2[:, 3] / 2
    
    inter_x1 = torch.max(box1_x1, box2_x1)
    inter_y1 = torch.max(box1_y1, box2_y1)
    inter_x2 = torch.min(box1_x2, box2_x2)
    inter_y2 = torch.min(box1_y2, box2_y2)
    
    inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)
    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)
    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)
    union_area = box1_area + box2_area - inter_area
    
    iou = inter_area / (union_area + 1e-6)
    return iou

def calculate_metrics(model, dataloader, device, img_size=800, use_tta=False):
    """í‰ê°€ ì§€í‘œ ê³„ì‚° (TTA ì˜µì…˜ ì¶”ê°€)"""
    model.eval()
    total_loss = 0
    total_box_loss = 0
    pixel_errors, x_errors, y_errors = [], [], []
    ious = []
    
    criterion_mse = nn.MSELoss()
    criterion_l1 = nn.L1Loss()
    
    with torch.no_grad():
        for images, boxes, points in dataloader:
            images, boxes, points = images.to(device), boxes.to(device), points.to(device)
            p_boxes, p_points = model(images)
            
            # Box Loss ê³„ì‚° (L1 30ë°° ê·¹ëŒ€í™” + MSE - IoU 0.70 ê°•ì œ ë°•ì œ)
            box_loss = (30.0 * criterion_l1(p_boxes, boxes)) + criterion_mse(p_boxes, boxes)
            
            # Point Loss ê³„ì‚° (Xì¶• 100ë°° ì˜ì  ê³ ì •, Yì¶• 0.5ë°° ìœ ì§€)
            x_diff = torch.abs(p_points[:, 0] - points[:, 0]) # ì¢Œìš° ì˜¤ì°¨
            y_diff = torch.abs(p_points[:, 1] - points[:, 1]) # ìƒí•˜ ì˜¤ì°¨
            # Xì¶• 100ë°° ê°€ì¤‘ì¹˜ë¡œ ì˜ì  ê³ ì •
            point_loss_weighted = (100.0 * torch.mean(x_diff**2)) + (0.5 * torch.mean(y_diff**2))
            
            total_box_loss += box_loss.item()
            
            # í†µí•© Loss (Box 20000ë°°, Point 200ë°° - ë°•ìŠ¤ ê°•ì œ ë°•ì œ)
            loss = (20000.0 * box_loss) + (200.0 * point_loss_weighted)
            total_loss += loss.item()
            
            # IoU ê³„ì‚°
            batch_iou = calculate_iou(p_boxes, boxes)
            ious.extend(batch_iou.cpu().numpy())
            
            # í”½ì…€ ì˜¤ì°¨ ë¶„ì„
            p_points_px = p_points * img_size
            t_points_px = points * img_size
            
            diff = torch.abs(p_points_px - t_points_px)
            x_errors.extend(diff[:, 0].cpu().numpy())
            y_errors.extend(diff[:, 1].cpu().numpy())
            pixel_errors.extend(torch.sqrt((diff**2).sum(dim=1)).cpu().numpy())
    
    pixel_errors = np.array(pixel_errors)
    ious = np.array(ious)
    
    model.train()
    return {
        'mse_loss': total_loss / len(dataloader),
        'box_loss': total_box_loss / len(dataloader),
        'mean_iou': ious.mean(),
        'box_hit_rate': (ious > 0.5).mean() * 100,
        'mpe': pixel_errors.mean(),
        'x_mae': np.mean(x_errors),
        'y_mae': np.mean(y_errors),
        'pck_5': (pixel_errors <= 5).mean() * 100,
        'pck_10': (pixel_errors <= 10).mean() * 100,
        'max_error': pixel_errors.max()
    }

def update_training_plot(history, fig, axes, best_epoch=None):
    """ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ (í™”ë©´ì— í‘œì‹œ)"""
    epochs = [h['epoch'] for h in history]
    
    # ëª¨ë“  ì„œë¸Œí”Œë¡¯ í´ë¦¬ì–´
    for ax_row in axes:
        for ax in ax_row:
            ax.clear()
    
    # ì²« ë²ˆì§¸ ì¤„: Loss ê´€ë ¨
    axes[0, 0].plot(epochs, [h['mse_loss'] for h in history], 'b-')
    axes[0, 0].set_title('Total MSE Loss (Validation)')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    if best_epoch is not None:
        axes[0, 0].axvline(x=best_epoch, color='red', linestyle='--', alpha=0.7, label=f'Best: {best_epoch}')
        axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    axes[0, 1].plot(epochs, [h['box_loss'] for h in history], 'purple')
    axes[0, 1].set_title('Box Loss (MSE)')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].grid(True, alpha=0.3)
    
    axes[0, 2].plot(epochs, [h['mpe'] for h in history], 'g-')
    axes[0, 2].set_title('Mean Pixel Error (MPE)')
    axes[0, 2].set_xlabel('Epoch')
    axes[0, 2].set_ylabel('Pixels')
    axes[0, 2].grid(True, alpha=0.3)
    
    # ë‘ ë²ˆì§¸ ì¤„: Box ê´€ë ¨
    axes[1, 0].plot(epochs, [h['mean_iou'] for h in history], 'brown')
    axes[1, 0].set_title('Mean IoU (mIoU)')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('IoU')
    axes[1, 0].set_ylim([0, 1])
    axes[1, 0].axhline(y=0.7, color='r', linestyle='--', alpha=0.5, label='Target: 0.7')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    axes[1, 1].plot(epochs, [h['box_hit_rate'] for h in history], 'darkred')
    axes[1, 1].set_title('Box Hit Rate (IoU > 0.5)')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Hit Rate (%)')
    axes[1, 1].set_ylim([0, 100])
    axes[1, 1].grid(True, alpha=0.3)
    
    axes[1, 2].plot(epochs, [h['x_mae'] for h in history], 'r-', label='X MAE')
    axes[1, 2].plot(epochs, [h['y_mae'] for h in history], 'orange', label='Y MAE')
    axes[1, 2].set_title('X/Y MAE')
    axes[1, 2].set_xlabel('Epoch')
    axes[1, 2].set_ylabel('Pixels')
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)
    
    # ì„¸ ë²ˆì§¸ ì¤„: Point ê´€ë ¨
    axes[2, 0].plot(epochs, [h['pck_5'] for h in history], 'm-')
    axes[2, 0].set_title('PCK @ 5px (%)')
    axes[2, 0].set_xlabel('Epoch')
    axes[2, 0].set_ylabel('Accuracy (%)')
    axes[2, 0].set_ylim([0, 100])
    axes[2, 0].grid(True, alpha=0.3)
    
    axes[2, 1].plot(epochs, [h['pck_10'] for h in history], 'c-')
    axes[2, 1].set_title('PCK @ 10px (%)')
    axes[2, 1].set_xlabel('Epoch')
    axes[2, 1].set_ylabel('Accuracy (%)')
    axes[2, 1].set_ylim([0, 100])
    axes[2, 1].grid(True, alpha=0.3)
    
    axes[2, 2].plot(epochs, [h['max_error'] for h in history], 'k-')
    axes[2, 2].set_title('Max Pixel Error')
    axes[2, 2].set_xlabel('Epoch')
    axes[2, 2].set_ylabel('Pixels')
    axes[2, 2].grid(True, alpha=0.3)
    
    fig.suptitle(f'Transfer Learning - Stage 7.0 (Epoch {epochs[-1]})', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.draw()
    plt.pause(0.01)  # í™”ë©´ ì—…ë°ì´íŠ¸

def save_final_plot(history, save_path, best_epoch=None):
    """ìµœì¢… ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥"""
    fig, axes = plt.subplots(3, 3, figsize=(20, 14))
    fig.suptitle('Transfer Learning - Box & Center Point Training Metrics (Final)', fontsize=16, fontweight='bold')
    
    epochs = [h['epoch'] for h in history]
    
    # ì²« ë²ˆì§¸ ì¤„: Loss ê´€ë ¨
    axes[0, 0].plot(epochs, [h['mse_loss'] for h in history], 'b-')
    axes[0, 0].set_title('Total MSE Loss (Validation)')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    if best_epoch is not None:
        axes[0, 0].axvline(x=best_epoch, color='red', linestyle='--', alpha=0.7, label=f'Best: {best_epoch}')
        axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    axes[0, 1].plot(epochs, [h['box_loss'] for h in history], 'purple')
    axes[0, 1].set_title('Box Loss (MSE)')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].grid(True, alpha=0.3)
    
    axes[0, 2].plot(epochs, [h['mpe'] for h in history], 'g-')
    axes[0, 2].set_title('Mean Pixel Error (MPE)')
    axes[0, 2].set_xlabel('Epoch')
    axes[0, 2].set_ylabel('Pixels')
    axes[0, 2].grid(True, alpha=0.3)
    
    # ë‘ ë²ˆì§¸ ì¤„: Box ê´€ë ¨
    axes[1, 0].plot(epochs, [h['mean_iou'] for h in history], 'brown')
    axes[1, 0].set_title('Mean IoU (mIoU)')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('IoU')
    axes[1, 0].set_ylim([0, 1])
    axes[1, 0].axhline(y=0.7, color='r', linestyle='--', alpha=0.5, label='Target: 0.7')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    axes[1, 1].plot(epochs, [h['box_hit_rate'] for h in history], 'darkred')
    axes[1, 1].set_title('Box Hit Rate (IoU > 0.5)')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Hit Rate (%)')
    axes[1, 1].set_ylim([0, 100])
    axes[1, 1].grid(True, alpha=0.3)
    
    axes[1, 2].plot(epochs, [h['x_mae'] for h in history], 'r-', label='X MAE')
    axes[1, 2].plot(epochs, [h['y_mae'] for h in history], 'orange', label='Y MAE')
    axes[1, 2].set_title('X/Y MAE')
    axes[1, 2].set_xlabel('Epoch')
    axes[1, 2].set_ylabel('Pixels')
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)
    
    # ì„¸ ë²ˆì§¸ ì¤„: Point ê´€ë ¨
    axes[2, 0].plot(epochs, [h['pck_5'] for h in history], 'm-')
    axes[2, 0].set_title('PCK @ 5px (%)')
    axes[2, 0].set_xlabel('Epoch')
    axes[2, 0].set_ylabel('Accuracy (%)')
    axes[2, 0].set_ylim([0, 100])
    axes[2, 0].grid(True, alpha=0.3)
    
    axes[2, 1].plot(epochs, [h['pck_10'] for h in history], 'c-')
    axes[2, 1].set_title('PCK @ 10px (%)')
    axes[2, 1].set_xlabel('Epoch')
    axes[2, 1].set_ylabel('Accuracy (%)')
    axes[2, 1].set_ylim([0, 100])
    axes[2, 1].grid(True, alpha=0.3)
    
    axes[2, 2].plot(epochs, [h['max_error'] for h in history], 'k-')
    axes[2, 2].set_title('Max Pixel Error')
    axes[2, 2].set_xlabel('Epoch')
    axes[2, 2].set_ylabel('Pixels')
    axes[2, 2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=100)
    print(f"\nğŸ“Š ìµœì¢… ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")
    plt.close()

# ==========================================
# 4. ë©”ì¸ í•™ìŠµ ë£¨í”„ (ì „ì²´ í•™ìŠµ ë²„ì „)
# ==========================================
def main():
    # ========== GPU ì •ë³´ ì¶œë ¥ ==========
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    use_cuda = torch.cuda.is_available()
    print("=" * 100)
    print(f"ğŸš€ PyTorch v{torch.__version__} / CUDA: {torch.version.cuda if use_cuda else 'N/A'}")
    if use_cuda:
        print(f"ğŸ¯ GPU: {torch.cuda.get_device_name(0)} (Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB)")
    print("=" * 100)
    
    print("\nğŸ”„ ì „ì´í•™ìŠµ ëª¨ë“œ ì‹œì‘ (Transfer Learning - Stage 2)")
    print("  ğŸ“Œ Best ê°€ì¤‘ì¹˜ ë¡œë“œ: cup_model_best.pth")
    print("  ğŸ¯ ê°•í™”ëœ ì¦ê°• ê¸°ë²• ì ìš© (45ë„ íšŒì „ + Perspective)")

    # ========== ë°ì´í„°ì…‹ ë¡œë“œ ==========
    print("\nğŸ“¦ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    train_dataset = CupDataset('./dataset/images/train', './dataset/labels/train', img_size=800, augment=False)
    val_dataset = CupDataset('./dataset/images/val', './dataset/labels/val', img_size=800, augment=False)
    print(f"  Train ìƒ˜í”Œ: {len(train_dataset)}")
    print(f"  Val ìƒ˜í”Œ: {len(val_dataset)}")
    
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True, num_workers=0, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, pin_memory=True, num_workers=0, drop_last=True)

    # ========== ëª¨ë¸ ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ==========
    print("\nğŸ§  ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model = YOLOFullTaskModel().to(device)
    
    # Stage 7.0: ìµœì‹  ê°€ì¤‘ì¹˜ ë¡œë“œ (ìµœê·¼ 4ê°œ ìŠ¤í…Œì´ì§€ë§Œ í™•ì¸)
    model_candidates = [
        ('cup_model_transfer6.2_best.pth', '6.2'),
        ('cup_model_transfer6.1_best.pth', '6.1'),
        ('cup_model_transfer6.0_best.pth', '6.0'),
        ('cup_model_transfer5.9_best.pth', '5.9')
    ]
    
    loaded = False
    for model_path, stage_name in model_candidates:
        if os.path.exists(model_path):
            state_dict = torch.load(model_path, map_location=device)
            model.load_state_dict(state_dict, strict=False)
            print(f"  âœ… Stage {stage_name} ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ")
            loaded = True
            break
    
    if not loaded:
        print("  âš ï¸  ìµœì‹  ê°€ì¤‘ì¹˜ ì—†ìŒ. ì²˜ìŒë¶€í„° í•™ìŠµ ì‹œì‘.")
    
    print("  âœ… YOLOFullTaskModel (Deep Multi-Head with BatchNorm)")

    # Stage 7.0: The Final Squeeze to IoU 0.7 (ê·¹ì´ˆì •ë°€ ì••ì°©)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.000002)  # 2e-6 (ê·¹ì´ˆì •ë°€)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10, verbose=True
    )
    
    # ì†ì‹¤ í•¨ìˆ˜: ë°•ìŠ¤ëŠ” L1 + MSE ì¡°í•©(í˜•íƒœ + í° ì˜¤ì°¨ ë°©ì§€), í¬ì¸íŠ¸ëŠ” MSE
    criterion_mse = nn.MSELoss()
    criterion_l1 = nn.L1Loss()  # ë°•ìŠ¤ ì •ë°€ë„ë¥¼ ìœ„í•´ ì¶”ê°€

    # Mixed Precision Scaler (GPU ì‚¬ìš© ì‹œë§Œ)
    scaler = torch.amp.GradScaler('cuda') if use_cuda else None
    
    # ========== ìƒˆë¡œìš´ CSV ë° ê·¸ë˜í”„ íŒŒì¼ ìƒì„± ==========
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f'transfer7.0_metrics_{timestamp}.csv'
    graph_filename = f'transfer7.0_metrics_{timestamp}.png'
    history = []
    start_epoch = 0
    
    print(f"\nğŸ“ ì „ì´í•™ìŠµ Stage 7.0 ì„¸ì…˜ ì‹œì‘ (The Final Squeeze - ë°•ìŠ¤ 20000ë°° ê·¹ì´ˆì •ë°€ ì••ì°©)")
    print(f"  ğŸ’¾ CSV íŒŒì¼: {csv_filename}")
    print(f"  ğŸ“Š ê·¸ë˜í”„ íŒŒì¼: {graph_filename}")
    
    # CSV í—¤ë” ì‘ì„±
    with open(csv_filename, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Epoch', 'Train_MSE_Loss', 'Train_Box_Loss', 'Train_Mean_IoU', 'Train_Box_Hit_Rate', 'Train_MPE', 'Train_X_MAE', 'Train_Y_MAE', 'Train_PCK@5px', 'Train_PCK@10px', 'Train_Max_Error',
                        'Val_MSE_Loss', 'Val_Box_Loss', 'Val_Mean_IoU', 'Val_Box_Hit_Rate', 'Val_MPE', 'Val_X_MAE', 'Val_Y_MAE', 'Val_PCK@5px', 'Val_PCK@10px', 'Val_Max_Error'])
    
    # ========== í•™ìŠµ ì„¤ì • ==========
    best_val_loss = float('inf')
    best_epoch = 0
    patience_limit = 60  # Early stopping patience (Stage 7.0 ìœ ì§€)
    patience_counter = 0
    best_model_path = 'cup_model_transfer7.0_best.pth'
    latest_model_path = 'cup_model_transfer7.0_latest.pth'
    epochs = 200  # 200 ì—í¬í¬ ëª©í‘œ (Stage 7.0)

    # ========== ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì´ˆê¸°í™” ==========
    plt.ion()  # Interactive mode ON
    fig, axes = plt.subplots(3, 3, figsize=(20, 14))
    plt.show(block=False)
    
    # ========== í•™ìŠµ ë£¨í”„ (Early Stopping í¬í•¨) ==========
    print("\n" + "=" * 100)
    print("ğŸ”¥ ì „ì´í•™ìŠµ Stage 7.0 ì‹œì‘! (The Final Squeeze to IoU 0.7 - Resolution: 800x800, Batch: 8, Epochs: 200, LR: 2e-6)")
    print("  ğŸ’£ ë°•ìŠ¤ 20000ë°° í­ê²©: L1 30ë°° ê·¹ëŒ€í™” (IoU 0.70 ê°•ì œ ë°•ì œ)")
    print("  ğŸ¯ Xì¶• 100ë°° ì˜ì  ê³ ì •: ì™„ì „ ì •ë°€ ì••ì°© (Yì¶• 0.5ë°° ìœ ì§€)")
    print("  ğŸ† 20000:200 ë°•ìŠ¤ ìš°ì„ : Box ê°•ì œ ë°•ì œ í›„ Point ì´ˆì •ë°€ ì¡°ì •")
    print("  ğŸ”¬ ê·¹ì´ˆì •ë°€ ëª¨ë“œ: 2e-6 + Epochs 200 + Patience 60")
    print(f"  ğŸ“Š Train Batches: {len(train_loader)} / Val Batches: {len(val_loader)}")
    print(f"  ğŸ“ Epoch: 1 ~ {epochs}")
    print(f"  ğŸ’¾ CSV: {csv_filename}")
    print(f"  ğŸ“Š ì‹¤ì‹œê°„ ê·¸ë˜í”„: í”„ë¡œê·¸ë¨ ì°½ì— í‘œì‹œ ì¤‘... (ìµœì¢… ì €ì¥: {graph_filename})")
    print(f"  âš ï¸  Early Stopping: Patience {patience_limit} epochs (Val Loss ê¸°ì¤€)")
    print("=" * 100 + "\n")

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        
        for images, boxes, points in train_loader:
            images = images.to(device, non_blocking=use_cuda)
            boxes = boxes.to(device, non_blocking=use_cuda)
            points = points.to(device, non_blocking=use_cuda)
            
            # ê¸°ìš¸ê¸° ì´ˆê¸°í™”
            optimizer.zero_grad()
            
            # Mixed Precisionìœ¼ë¡œ í•™ìŠµ (GPU ì‚¬ìš©ì‹œë§Œ)
            if use_cuda:
                with torch.amp.autocast('cuda'):
                    p_boxes, p_points = model(images)
                    
                    # ë°•ìŠ¤: 20000ë°° í­ê²© (L1 30ë°° ê·¹ëŒ€í™” - IoU 0.70 ê°•ì œ ë°•ì œ)
                    box_loss = (30.0 * criterion_l1(p_boxes, boxes)) + criterion_mse(p_boxes, boxes)
                    
                    # ì¤‘ì‹¬ì : Xì¶• 100ë°° ì˜ì  ê³ ì • (Yì¶• 0.5ë°° ìœ ì§€)
                    x_diff = torch.abs(p_points[:, 0] - points[:, 0])
                    y_diff = torch.abs(p_points[:, 1] - points[:, 1])
                    point_loss_weighted = (100.0 * torch.mean(x_diff**2)) + (0.5 * torch.mean(y_diff**2))
                    
                    # ìµœì¢… ê°€ì¤‘ì¹˜: Box 20000 : Point 200 (ë°•ìŠ¤ ê°•ì œ ë°•ì œ)
                    loss = (20000.0 * box_loss) + (200.0 * point_loss_weighted)
                
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                p_boxes, p_points = model(images)
                
                # ë°•ìŠ¤: 20000ë°° í­ê²© (L1 30ë°° ê·¹ëŒ€í™” - IoU 0.70 ê°•ì œ ë°•ì œ)
                box_loss = (30.0 * criterion_l1(p_boxes, boxes)) + criterion_mse(p_boxes, boxes)
                
                # ì¤‘ì‹¬ì : Xì¶• 100ë°° ì˜ì  ê³ ì • (Yì¶• 0.5ë°° ìœ ì§€)
                x_diff = torch.abs(p_points[:, 0] - points[:, 0])
                y_diff = torch.abs(p_points[:, 1] - points[:, 1])
                point_loss_weighted = (100.0 * torch.mean(x_diff**2)) + (0.5 * torch.mean(y_diff**2))
                
                # ìµœì¢… ê°€ì¤‘ì¹˜: Box 20000 : Point 200 (ë°•ìŠ¤ ê°•ì œ ë°•ì œ)
                loss = (20000.0 * box_loss) + (200.0 * point_loss_weighted)
                loss.backward()
                optimizer.step()
            
            total_loss += loss.item()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if use_cuda:
            torch.cuda.empty_cache()

        # ì—í¬í¬ ì¢…ë£Œ í›„ í‰ê°€
        train_metrics = calculate_metrics(model, train_loader, device, img_size=800)
        val_metrics = calculate_metrics(model, val_loader, device, img_size=800)
        
        # Learning Rate Scheduler ì—…ë°ì´íŠ¸
        scheduler.step(val_metrics['mse_loss'])
        
        # íˆìŠ¤í† ë¦¬ì— ì €ì¥
        combined_metrics = {'epoch': epoch + 1}
        combined_metrics.update({f'train_{k}': v for k, v in train_metrics.items()})
        combined_metrics.update({f'val_{k}': v for k, v in val_metrics.items()})
        history.append(combined_metrics)
        
        # CMD ì¶œë ¥ (ë§¤ ì—í¬í¬ë§ˆë‹¤ ì¶œë ¥)
        print(f"\n[Epoch {epoch+1}/{epochs}]")
        print(f"  [Train] Total Loss: {train_metrics['mse_loss']:.6f} | Box Loss: {train_metrics['box_loss']:.6f} | MPE: {train_metrics['mpe']:.2f}px")
        print(f"  [Train] Mean IoU: {train_metrics['mean_iou']:.4f} | Box Hit Rate: {train_metrics['box_hit_rate']:.2f}% | PCK@5px: {train_metrics['pck_5']:.2f}%")
        print(f"  [Val]   Total Loss: {val_metrics['mse_loss']:.6f} | Box Loss: {val_metrics['box_loss']:.6f} | MPE: {val_metrics['mpe']:.2f}px")
        print(f"  [Val]   Mean IoU: {val_metrics['mean_iou']:.4f} | Box Hit Rate: {val_metrics['box_hit_rate']:.2f}% | PCK@5px: {val_metrics['pck_5']:.2f}% â­")
        print(f"  [LR]    {optimizer.param_groups[0]['lr']:.8f}")
        print("-" * 100)
        
        # CSVì— ì €ì¥
        with open(csv_filename, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                combined_metrics['epoch'],
                f"{train_metrics['mse_loss']:.6f}",
                f"{train_metrics['box_loss']:.6f}",
                f"{train_metrics['mean_iou']:.4f}",
                f"{train_metrics['box_hit_rate']:.2f}",
                f"{train_metrics['mpe']:.2f}",
                f"{train_metrics['x_mae']:.2f}",
                f"{train_metrics['y_mae']:.2f}",
                f"{train_metrics['pck_5']:.2f}",
                f"{train_metrics['pck_10']:.2f}",
                f"{train_metrics['max_error']:.2f}",
                f"{val_metrics['mse_loss']:.6f}",
                f"{val_metrics['box_loss']:.6f}",
                f"{val_metrics['mean_iou']:.4f}",
                f"{val_metrics['box_hit_rate']:.2f}",
                f"{val_metrics['mpe']:.2f}",
                f"{val_metrics['x_mae']:.2f}",
                f"{val_metrics['y_mae']:.2f}",
                f"{val_metrics['pck_5']:.2f}",
                f"{val_metrics['pck_10']:.2f}",
                f"{val_metrics['max_error']:.2f}"
            ])
        
        # ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ (í™”ë©´ì— í‘œì‹œ)
        val_history = [{'epoch': h['epoch'], **{k.replace('val_', ''): v for k, v in h.items() if k.startswith('val_')}} for h in history]
        update_training_plot(val_history, fig, axes, best_epoch=best_epoch)
        
        # ëª¨ë¸ ì €ì¥
        # 1. ìµœì‹  ëª¨ë¸ ì €ì¥ (ë®ì–´ì“°ê¸°)
        torch.save(model.state_dict(), latest_model_path)
        
        # 2. Best ëª¨ë¸ ì €ì¥ + Early Stopping
        if val_metrics['mse_loss'] < best_val_loss:
            best_val_loss = val_metrics['mse_loss']
            best_epoch = epoch + 1
            patience_counter = 0  # ê°œì„ ë˜ì—ˆìœ¼ë¯€ë¡œ ì¹´ìš´í„° ë¦¬ì…‹
            torch.save(model.state_dict(), best_model_path)
            print(f"  â­ Best ëª¨ë¸ ì €ì¥! (Val Loss: {best_val_loss:.6f})")
        else:
            patience_counter += 1
            print(f"  âš ï¸  Early Stopping Counter: {patience_counter}/{patience_limit}")
            
            # Early Stopping ë°œë™
            if patience_counter >= patience_limit:
                print(f"\nğŸ›‘ Early Stopping ë°œë™! (Patience {patience_limit} epochs ë„ë‹¬)")
                print(f"  Best Epoch: {best_epoch} (Val Loss: {best_val_loss:.6f})")
                print(f"  í˜„ì¬ Epoch: {epoch + 1}")
                break
    
    # ========== ìµœì¢… ë³´ê³ ì„œ ==========
    print("\n" + "=" * 100)
    print("ğŸ‰ í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("=" * 100)
    
    # ìµœì¢… ë©”íŠ¸ë¦­ ì¶œë ¥
    final_metrics = history[-1]
    print(f"\n[ìµœì¢… ì„±ëŠ¥ (Epoch {final_metrics['epoch']}) - Validation Set]")
    print(f"\nğŸ“¦ ë°•ìŠ¤ ê²€ì¶œ ì„±ëŠ¥:")
    print(f"  Box Loss (MSE)     : {final_metrics['val_box_loss']:.6f}")
    print(f"  Mean IoU (mIoU)    : {final_metrics['val_mean_iou']:.4f} {'âœ… ëª©í‘œë‹¬ì„±!' if final_metrics['val_mean_iou'] >= 0.7 else ''}")
    print(f"  Box Hit Rate       : {final_metrics['val_box_hit_rate']:.2f}%")
    print(f"\nğŸ¯ ì¤‘ì‹¬ì  ê²€ì¶œ ì„±ëŠ¥:")
    print(f"  Total Loss (ê°€ì¤‘)  : {final_metrics['val_mse_loss']:.6f}")
    print(f"  MPE                : {final_metrics['val_mpe']:.2f} px")
    print(f"  X MAE              : {final_metrics['val_x_mae']:.2f} px")
    print(f"  Y MAE              : {final_metrics['val_y_mae']:.2f} px")
    print(f"  PCK @ 5px          : {final_metrics['val_pck_5']:.2f}%")
    print(f"  PCK @ 10px         : {final_metrics['val_pck_10']:.2f}%")
    print(f"  Max Error          : {final_metrics['val_max_error']:.2f} px")
    
    # Interactive mode ì¢…ë£Œ ë° ìµœì¢… ê·¸ë˜í”„ ì €ì¥
    plt.ioff()
    plt.close(fig)
    
    # ìµœì¢… ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥
    val_history = [{'epoch': h['epoch'], **{k.replace('val_', ''): v for k, v in h.items() if k.startswith('val_')}} for h in history]
    save_final_plot(val_history, save_path=graph_filename, best_epoch=best_epoch)
    
    print(f"\nğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
    print(f"  - ìµœì‹  ëª¨ë¸: {latest_model_path} (ë§ˆì§€ë§‰ ì—í¬í¬)")
    print(f"  - ìµœê³  ëª¨ë¸: {best_model_path} (Epoch {best_epoch}, Val Loss: {best_val_loss:.6f})")
    print(f"  - ë©”íŠ¸ë¦­ CSV: {csv_filename}")
    print(f"  - í•™ìŠµ ê·¸ë˜í”„: {graph_filename}")
    print(f"\nğŸ’¡ ì‚¬ìš© íŒ:")
    print(f"  - Best ëª¨ë¸({best_model_path})ì„ í”„ë¡œë•ì…˜ì— ì‚¬ìš©í•˜ì„¸ìš”")
    print(f"  - Early Stoppingìœ¼ë¡œ ê³¼ì í•© ë°©ì§€ (Best: Epoch {best_epoch})")
    print("=" * 100)

if __name__ == "__main__":
    main()